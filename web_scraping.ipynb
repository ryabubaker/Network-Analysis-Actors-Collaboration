{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryabubaker/Network-Analysis-Actors-Collaboration/blob/main/web_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K1zBL29CoLa"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "#scraping movies from 2017-01-01 to 2023-12-30\n",
        "base_url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2012-01-01,2015-12-31&user_rating=5.0,10.0&languages=en\"\n",
        "movies_per_page = 50\n",
        "num_movies = 9674 \n",
        "num_pages = num_movies // movies_per_page + 1\n",
        "movies = set()\n",
        "\n",
        "# Define a function to scrape a single page of movies\n",
        "def scrape_page(page_num):\n",
        "    start = (page_num - 1) * movies_per_page + 1\n",
        "    url = base_url + \"&start=\" + str(start)\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    page_movies = soup.find_all('div', class_='lister-item mode-advanced')\n",
        "    for movie in page_movies:\n",
        "        year = re.findall('\\d{4}', movie.h3.find_all('span', class_='lister-item-year text-muted unbold')[0].text.strip())[0]\n",
        "        if int(year) < 2000:\n",
        "            continue\n",
        "        title = movie.h3.a.text\n",
        "        movie_id = movie.h3.a['href'].split('/')[-2]\n",
        "        crew = [a.text for a in movie.select('a[href*=\"/name/\"]')]\n",
        "        director = crew[0] if crew else 'N/A'\n",
        "        stars = crew[1:]\n",
        "        votes = movie.find('span', class_='value').text if movie.find('span', class_='value') else 'N/A'\n",
        "        movie_tuple = (title, year, movie_id, director, tuple(stars), votes)\n",
        "        if movie_tuple not in movies:\n",
        "            movies.add(movie_tuple)\n",
        "\n",
        "# Create a thread pool and submit tasks to scrape each page\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    for page_num in range(1, num_pages+1):\n",
        "        executor.submit(scrape_page, page_num)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "# Create a pandas DataFrame from the set of tuples and save it to a CSV file\n",
        "df = pd.DataFrame(list(movies), columns=['Title', 'Year', 'Movie ID', 'Director', 'Stars', 'Votes'])\n",
        "df.to_csv('movie-2012-2015.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scraping movies from 2017-01-01 to 2023-12-30\n",
        "base_url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2016-01-01,2019-12-31&user_rating=5.0,10.0&languages=en\"\n",
        "movies_per_page = 50\n",
        "num_movies = 9949 \n",
        "num_pages = num_movies // movies_per_page + 1\n",
        "movies = set()\n",
        "\n",
        "# Define a function to scrape a single page of movies\n",
        "def scrape_page(page_num):\n",
        "    start = (page_num - 1) * movies_per_page + 1\n",
        "    url = base_url + \"&start=\" + str(start)\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    page_movies = soup.find_all('div', class_='lister-item mode-advanced')\n",
        "    for movie in page_movies:\n",
        "        year = re.findall('\\d{4}', movie.h3.find_all('span', class_='lister-item-year text-muted unbold')[0].text.strip())[0]\n",
        "        if int(year) < 2000:\n",
        "            continue\n",
        "        title = movie.h3.a.text\n",
        "        movie_id = movie.h3.a['href'].split('/')[-2]\n",
        "        crew = [a.text for a in movie.select('a[href*=\"/name/\"]')]\n",
        "        director = crew[0] if crew else 'N/A'\n",
        "        stars = crew[1:]\n",
        "        votes = movie.find('span', class_='value').text if movie.find('span', class_='value') else 'N/A'\n",
        "        movie_tuple = (title, year, movie_id, director, tuple(stars), votes)\n",
        "        if movie_tuple not in movies:\n",
        "            movies.add(movie_tuple)\n",
        "\n",
        "# Create a thread pool and submit tasks to scrape each page\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    for page_num in range(1, num_pages+1):\n",
        "        executor.submit(scrape_page, page_num)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "# Create a pandas DataFrame from the set of tuples and save it to a CSV file\n",
        "df = pd.DataFrame(list(movies), columns=['Title', 'Year', 'Movie ID', 'Director', 'Stars', 'Votes'])\n",
        "df.to_csv('movie-2015-2019.csv', index=False)"
      ],
      "metadata": {
        "id": "eaIMxX_9Dxx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scraping movies from 2017-01-01 to 2023-12-30\n",
        "base_url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2019-01-01,2023-12-31&user_rating=5.0,10.0&languages=en\"\n",
        "movies_per_page = 50\n",
        "num_movies = 9125\n",
        "num_pages = num_movies // movies_per_page + 1\n",
        "movies = set()\n",
        "\n",
        "# Define a function to scrape a single page of movies\n",
        "def scrape_page(page_num):\n",
        "    start = (page_num - 1) * movies_per_page + 1\n",
        "    url = base_url + \"&start=\" + str(start)\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    page_movies = soup.find_all('div', class_='lister-item mode-advanced')\n",
        "    for movie in page_movies:\n",
        "        year = re.findall('\\d{4}', movie.h3.find_all('span', class_='lister-item-year text-muted unbold')[0].text.strip())[0]\n",
        "        if int(year) < 2000:\n",
        "            continue\n",
        "        title = movie.h3.a.text\n",
        "        movie_id = movie.h3.a['href'].split('/')[-2]\n",
        "        crew = [a.text for a in movie.select('a[href*=\"/name/\"]')]\n",
        "        director = crew[0] if crew else 'N/A'\n",
        "        stars = crew[1:]\n",
        "        votes = movie.find('span', class_='value').text if movie.find('span', class_='value') else 'N/A'\n",
        "        movie_tuple = (title, year, movie_id, director, tuple(stars), votes)\n",
        "        if movie_tuple not in movies:\n",
        "            movies.add(movie_tuple)\n",
        "\n",
        "# Create a thread pool and submit tasks to scrape each page\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    for page_num in range(1, num_pages+1):\n",
        "        executor.submit(scrape_page, page_num)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "# Create a pandas DataFrame from the set of tuples and save it to a CSV file\n",
        "df = pd.DataFrame(list(movies), columns=['Title', 'Year', 'Movie ID', 'Director', 'Stars', 'Votes'])\n",
        "df.to_csv('movie-2019-2023.csv', index=False)"
      ],
      "metadata": {
        "id": "h1NMc9umHHSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2009-01-01,2012-12-31&user_rating=5.0,10.0&languages=en\"\n",
        "movies_per_page = 50\n",
        "num_movies = 8748\n",
        "num_pages = num_movies // movies_per_page + 1\n",
        "movies = set()\n",
        "\n",
        "# Define a function to scrape a single page of movies\n",
        "def scrape_page(page_num):\n",
        "    start = (page_num - 1) * movies_per_page + 1\n",
        "    url = base_url + \"&start=\" + str(start)\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    page_movies = soup.find_all('div', class_='lister-item mode-advanced')\n",
        "    for movie in page_movies:\n",
        "        year = re.findall('\\d{4}', movie.h3.find_all('span', class_='lister-item-year text-muted unbold')[0].text.strip())[0]\n",
        "        if int(year) < 2000:\n",
        "            continue\n",
        "        title = movie.h3.a.text\n",
        "        movie_id = movie.h3.a['href'].split('/')[-2]\n",
        "        crew = [a.text for a in movie.select('a[href*=\"/name/\"]')]\n",
        "        director = crew[0] if crew else 'N/A'\n",
        "        stars = crew[1:]\n",
        "        votes = movie.find('span', class_='value').text if movie.find('span', class_='value') else 'N/A'\n",
        "        movie_tuple = (title, year, movie_id, director, tuple(stars), votes)\n",
        "        if movie_tuple not in movies:\n",
        "            movies.add(movie_tuple)\n",
        "\n",
        "# Create a thread pool and submit tasks to scrape each page\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    for page_num in range(1, num_pages+1):\n",
        "        executor.submit(scrape_page, page_num)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "# Create a pandas DataFrame from the set of tuples and save it to a CSV file\n",
        "df = pd.DataFrame(list(movies), columns=['Title', 'Year', 'Movie ID', 'Director', 'Stars', 'Votes'])\n",
        "df.to_csv('movie-2009-2012.csv', index=False)"
      ],
      "metadata": {
        "id": "7t_ol0MMLMtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2005-01-01,2009-12-31&user_rating=5.0,10.0&languages=en\"\n",
        "movies_per_page = 50\n",
        "num_movies = 8057\n",
        "num_pages = num_movies // movies_per_page + 1\n",
        "movies = set()\n",
        "\n",
        "# Define a function to scrape a single page of movies\n",
        "def scrape_page(page_num):\n",
        "    start = (page_num - 1) * movies_per_page + 1\n",
        "    url = base_url + \"&start=\" + str(start)\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    page_movies = soup.find_all('div', class_='lister-item mode-advanced')\n",
        "    for movie in page_movies:\n",
        "        year = re.findall('\\d{4}', movie.h3.find_all('span', class_='lister-item-year text-muted unbold')[0].text.strip())[0]\n",
        "        if int(year) < 2000:\n",
        "            continue\n",
        "        title = movie.h3.a.text\n",
        "        movie_id = movie.h3.a['href'].split('/')[-2]\n",
        "        crew = [a.text for a in movie.select('a[href*=\"/name/\"]')]\n",
        "        director = crew[0] if crew else 'N/A'\n",
        "        stars = crew[1:]\n",
        "        votes = movie.find('span', class_='value').text if movie.find('span', class_='value') else 'N/A'\n",
        "        movie_tuple = (title, year, movie_id, director, tuple(stars), votes)\n",
        "        if movie_tuple not in movies:\n",
        "            movies.add(movie_tuple)\n",
        "\n",
        "# Create a thread pool and submit tasks to scrape each page\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    for page_num in range(1, num_pages+1):\n",
        "        executor.submit(scrape_page, page_num)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "# Create a pandas DataFrame from the set of tuples and save it to a CSV file\n",
        "df = pd.DataFrame(list(movies), columns=['Title', 'Year', 'Movie ID', 'Director', 'Stars', 'Votes'])\n",
        "df.to_csv('movie-2005-2009.csv', index=False)"
      ],
      "metadata": {
        "id": "IwHl0wY6L1iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2005-12-31&user_rating=5.0,10.0&languages=en\"\n",
        "movies_per_page = 50\n",
        "num_movies = 6615\n",
        "num_pages = num_movies // movies_per_page + 1\n",
        "movies = set()\n",
        "\n",
        "# Define a function to scrape a single page of movies\n",
        "def scrape_page(page_num):\n",
        "    start = (page_num - 1) * movies_per_page + 1\n",
        "    url = base_url + \"&start=\" + str(start)\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    page_movies = soup.find_all('div', class_='lister-item mode-advanced')\n",
        "    for movie in page_movies:\n",
        "        year = re.findall('\\d{4}', movie.h3.find_all('span', class_='lister-item-year text-muted unbold')[0].text.strip())[0]\n",
        "        if int(year) < 2000:\n",
        "            continue\n",
        "        title = movie.h3.a.text\n",
        "        movie_id = movie.h3.a['href'].split('/')[-2]\n",
        "        crew = [a.text for a in movie.select('a[href*=\"/name/\"]')]\n",
        "        director = crew[0] if crew else 'N/A'\n",
        "        stars = crew[1:]\n",
        "        votes = movie.find('span', class_='value').text if movie.find('span', class_='value') else 'N/A'\n",
        "        movie_tuple = (title, year, movie_id, director, tuple(stars), votes)\n",
        "        if movie_tuple not in movies:\n",
        "            movies.add(movie_tuple)\n",
        "\n",
        "# Create a thread pool and submit tasks to scrape each page\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    for page_num in range(1, num_pages+1):\n",
        "        executor.submit(scrape_page, page_num)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "# Create a pandas DataFrame from the set of tuples and save it to a CSV file\n",
        "df = pd.DataFrame(list(movies), columns=['Title', 'Year', 'Movie ID', 'Director', 'Stars', 'Votes'])\n",
        "df.to_csv('movie-2000-2005.csv', index=False)"
      ],
      "metadata": {
        "id": "UMthXdV9MZzy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}